{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDU SCE 信息与内容安全-虚假人脸检测\n",
    "\n",
    "给定一个人脸数据集，其中包含1999张真实人脸，1999张虚假人脸。将其中500\n",
    "张真实人脸和500张虚假人脸作为训练集，其余作为测试集。\n",
    "\n",
    "根据给定数据集训练训练一个虚假人脸检测器，该检测器本质就是一个二分类器。要求利用Pytorch框架任意设计一种神经网络模型进行分类，分类准确率越高越好(分类准确率和得分不相关)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Face_Forensic-master\n",
    "    Autor: ShenaoW\n",
    "    Date: May 2nd, 2022\n",
    "    Model: MesoNet (Best Acc ≈ 65.4%)\n",
    "           ResNet18 Pretrained (Best Acc ≈ 99%)\n",
    "           ResNet18 (trained with the given data only) (Best Acc ≈ 97%) \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from torchvision import models, datasets, transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Generation\n",
    "从原数据生成labels.csv\n",
    "每行数据为 (png_path, label)\n",
    "用于构造dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pic_path():\n",
    "\n",
    "    real_list = []\n",
    "    fake_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\"data/0_real\", topdown=False):\n",
    "        for file in files:\n",
    "            real_list.append(file)\n",
    "    real_list.sort()\n",
    "    \n",
    "    for root, dirs, files in os.walk(\"data/1_fake\", topdown=False):\n",
    "        for file in files:\n",
    "            fake_list.append(file)\n",
    "    fake_list.sort()\n",
    "\n",
    "    return real_list, fake_list\n",
    "\n",
    "\n",
    "def gen_label():\n",
    "\n",
    "    real_list, fake_list = get_pic_path()\n",
    "\n",
    "    real_writer = csv.writer(open(\"data/real_labels.csv\", \"w\", encoding=\"utf8\"))\n",
    "\n",
    "    for real_png in real_list:\n",
    "        real_writer.writerow((real_png, \"1\"))\n",
    "\n",
    "    fake_writer = csv.writer(open(\"data/fake_labels.csv\", \"w\", encoding=\"utf8\"))\n",
    "\n",
    "    for fake_png in fake_list:\n",
    "        fake_writer.writerow((fake_png, \"0\"))\n",
    "    \n",
    "\n",
    "# gen_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        # transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset\n",
    "\n",
    "#### 通过重写torch.utils.data.Dataset自定义数据集\n",
    "\n",
    "annotations_file: real_labels.csv/fake_labels.csv\n",
    "\n",
    "img_dir: \"data/0_real\"/\"data/1_fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from torchvision.io import read_image\n",
    "\n",
    "# class FaceDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file, header=None)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label\n",
    "\n",
    "# real_dataset = FaceDataset(\"data/real_labels.csv\", \"data/0_real\", transform=data_transforms)\n",
    "# fake_dataset = FaceDataset(\"data/fake_labels.csv\", \"data/1_fake\", transform=data_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过torchvision.datasets.ImageFolder构造数据集\n",
    "\n",
    "该方法比重写torch.utils.data.Dataset更简单，标签以文件名自动加载\n",
    "\n",
    "为了后续方便划分，需要将real_data和fake_data区分，划分得到两个子集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(\"data\", transform=data_transforms)\n",
    "real_dataset = Subset(full_dataset, range(1999))\n",
    "fake_dataset = Subset(full_dataset, range(1999, 3998))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "\n",
    "train_dataset : real_face和fake_face各400张\n",
    "\n",
    "dev_dataset : real_face和fake_face各100张 ( 按照题目要求共500张用于训练，train : dev = 8 : 2 )\n",
    "\n",
    "test_dataset : real_face和fake_face各1000张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(real_dataset)==1999 and len(fake_dataset)==1999\n",
    "\n",
    "train_size, dev_size, test_size  = int(500*0.8), 500-int(500*0.8), 1499\n",
    "\n",
    "assert train_size + dev_size + test_size == 1999\n",
    "\n",
    "train_dataset = ConcatDataset((\n",
    "\n",
    "    Subset(real_dataset, range(train_size)), \n",
    "\n",
    "    Subset(fake_dataset, range(train_size))\n",
    "\n",
    "    ))\n",
    "\n",
    "dev_dataset = ConcatDataset((\n",
    "    \n",
    "    Subset(real_dataset, range(dev_size)), \n",
    "\n",
    "    Subset(fake_dataset, range(dev_size))\n",
    "\n",
    "    ))\n",
    "\n",
    "test_dataset = ConcatDataset(( \n",
    "    \n",
    "    Subset(real_dataset, range(test_size)), \n",
    "\n",
    "    Subset(fake_dataset, range(test_size))\n",
    "    \n",
    "    ))\n",
    "\n",
    "assert len(train_dataset) == 2*train_size\n",
    "assert len(dev_dataset) == 2*dev_size\n",
    "assert len(test_dataset) == 2*test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "train_dataset_size = len(train_dataset)\n",
    "dev_dataset_size = len(dev_dataset)\n",
    "test_dataset_size = len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MesoNet\n",
    "\n",
    "best acc在70%左右，效果不理想，后面改用ResNet\n",
    "\n",
    "\n",
    "cite：https://github.com/HongguLiu/MesoNet-Pytorch\n",
    "\n",
    "Autor: Honggu Liu\n",
    "\n",
    "Date: July 4, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Meso4(nn.Module):\n",
    "# \t\"\"\"\n",
    "# \tPytorch Implemention of Meso4\n",
    "# \tAutor: Honggu Liu\n",
    "# \tDate: July 4, 2019\n",
    "# \t\"\"\"\n",
    "# \tdef __init__(self, num_classes=2)\n",
    "# \t\tsuper(Meso4, self).__init__()\n",
    "# \t\tself.num_classes = num_classes\n",
    "# \t\tself.conv1 = nn.Conv2d(3, 8, 3, padding=1, bias=False)\n",
    "# \t\tself.bn1 = nn.BatchNorm2d(8)\n",
    "# \t\tself.relu = nn.ReLU(inplace=True)\n",
    "# \t\tself.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "# \t\tself.conv2 = nn.Conv2d(8, 8, 5, padding=2, bias=False)\n",
    "# \t\tself.bn2 = nn.BatchNorm2d(16)\n",
    "# \t\tself.conv3 = nn.Conv2d(8, 16, 5, padding=2, bias=False)\n",
    "# \t\tself.conv4 = nn.Conv2d(16, 16, 5, padding=2, bias=False)\n",
    "# \t\tself.maxpooling1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "# \t\tself.maxpooling2 = nn.MaxPool2d(kernel_size=(4, 4))\n",
    "# \t\t#flatten: x = x.view(x.size(0), -1)\n",
    "# \t\tself.dropout = nn.Dropout2d(0.5)\n",
    "# \t\tself.fc1 = nn.Linear(16*8*8, 16)\n",
    "# \t\tself.fc2 = nn.Linear(16, num_classes)\n",
    "\n",
    "# \tdef forward(self, input):\n",
    "# \t\tx = self.conv1(input) #(8, 256, 256)\n",
    "# \t\tx = self.relu(x)\n",
    "# \t\tx = self.bn1(x)\n",
    "# \t\tx = self.maxpooling1(x) #(8, 128, 128)\n",
    "\n",
    "# \t\tx = self.conv2(x) #(8, 128, 128)\n",
    "# \t\tx = self.relu(x)\n",
    "# \t\tx = self.bn1(x)\n",
    "# \t\tx = self.maxpooling1(x) #(8, 64, 64)\n",
    "\n",
    "# \t\tx = self.conv3(x) #(16, 64, 64)\n",
    "# \t\tx = self.relu(x)\n",
    "# \t\tx = self.bn2(x)\n",
    "# \t\tx = self.maxpooling1(x) #(16, 32, 32)\n",
    "\n",
    "# \t\tx = self.conv4(x) #(16, 32, 32)\n",
    "# \t\tx = self.relu(x)\n",
    "# \t\tx = self.bn2(x)\n",
    "# \t\tx = self.maxpooling2(x) #(16, 8, 8)\n",
    "\n",
    "# \t\tx = x.view(x.size(0), -1) #(Batch, 16*8*8)\n",
    "# \t\tx = self.dropout(x)\n",
    "# \t\tx = self.fc1(x) #(Batch, 16)\n",
    "# \t\tx = self.leakyrelu(x)\n",
    "# \t\tx = self.dropout(x)\n",
    "# \t\tx = self.fc2(x)\n",
    "\n",
    "# \t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetPretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetPretrained, self).__init__()\n",
    "        resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "        self.model = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "epoch train loss: 0.0384 Acc: 0.5138\n",
      "epoch dev loss: 0.0268 Acc: 0.5200\n",
      "Epoch 2/50\n",
      "----------\n",
      "epoch train loss: 0.0107 Acc: 0.6388\n",
      "epoch dev loss: 0.0155 Acc: 0.6100\n",
      "Epoch 3/50\n",
      "----------\n",
      "epoch train loss: 0.0095 Acc: 0.6913\n",
      "epoch dev loss: 0.0153 Acc: 0.5600\n",
      "Epoch 4/50\n",
      "----------\n",
      "epoch train loss: 0.0093 Acc: 0.7100\n",
      "epoch dev loss: 0.0130 Acc: 0.6250\n",
      "Epoch 5/50\n",
      "----------\n",
      "epoch train loss: 0.0087 Acc: 0.7425\n",
      "epoch dev loss: 0.0116 Acc: 0.6450\n",
      "Epoch 6/50\n",
      "----------\n",
      "epoch train loss: 0.0081 Acc: 0.7862\n",
      "epoch dev loss: 0.0142 Acc: 0.6500\n",
      "Epoch 7/50\n",
      "----------\n",
      "epoch train loss: 0.0077 Acc: 0.7750\n",
      "epoch dev loss: 0.0113 Acc: 0.6750\n",
      "Epoch 8/50\n",
      "----------\n",
      "epoch train loss: 0.0074 Acc: 0.7887\n",
      "epoch dev loss: 0.0276 Acc: 0.6100\n",
      "Epoch 9/50\n",
      "----------\n",
      "epoch train loss: 0.0070 Acc: 0.7925\n",
      "epoch dev loss: 0.0156 Acc: 0.6850\n",
      "Epoch 10/50\n",
      "----------\n",
      "epoch train loss: 0.0068 Acc: 0.8288\n",
      "epoch dev loss: 0.0218 Acc: 0.5200\n",
      "Epoch 11/50\n",
      "----------\n",
      "epoch train loss: 0.0062 Acc: 0.8275\n",
      "epoch dev loss: 0.0124 Acc: 0.6850\n",
      "Epoch 12/50\n",
      "----------\n",
      "epoch train loss: 0.0057 Acc: 0.8400\n",
      "epoch dev loss: 0.0173 Acc: 0.6900\n",
      "Epoch 13/50\n",
      "----------\n",
      "epoch train loss: 0.0053 Acc: 0.8625\n",
      "epoch dev loss: 0.0242 Acc: 0.5600\n",
      "Epoch 14/50\n",
      "----------\n",
      "epoch train loss: 0.0051 Acc: 0.8763\n",
      "epoch dev loss: 0.0258 Acc: 0.5850\n",
      "Epoch 15/50\n",
      "----------\n",
      "epoch train loss: 0.0054 Acc: 0.8500\n",
      "epoch dev loss: 0.0334 Acc: 0.6250\n",
      "Epoch 16/50\n",
      "----------\n",
      "epoch train loss: 0.0047 Acc: 0.8850\n",
      "epoch dev loss: 0.0063 Acc: 0.8450\n",
      "Epoch 17/50\n",
      "----------\n",
      "epoch train loss: 0.0037 Acc: 0.9287\n",
      "epoch dev loss: 0.0050 Acc: 0.8900\n",
      "Epoch 18/50\n",
      "----------\n",
      "epoch train loss: 0.0031 Acc: 0.9375\n",
      "epoch dev loss: 0.0049 Acc: 0.9300\n",
      "Epoch 19/50\n",
      "----------\n",
      "epoch train loss: 0.0026 Acc: 0.9400\n",
      "epoch dev loss: 0.0028 Acc: 0.9200\n",
      "Epoch 20/50\n",
      "----------\n",
      "epoch train loss: 0.0033 Acc: 0.9250\n",
      "epoch dev loss: 0.0028 Acc: 0.9300\n",
      "Epoch 21/50\n",
      "----------\n",
      "epoch train loss: 0.0025 Acc: 0.9450\n",
      "epoch dev loss: 0.0031 Acc: 0.9650\n",
      "Epoch 22/50\n",
      "----------\n",
      "epoch train loss: 0.0018 Acc: 0.9700\n",
      "epoch dev loss: 0.0052 Acc: 0.8650\n",
      "Epoch 23/50\n",
      "----------\n",
      "epoch train loss: 0.0016 Acc: 0.9688\n",
      "epoch dev loss: 0.0018 Acc: 0.9850\n",
      "Epoch 24/50\n",
      "----------\n",
      "epoch train loss: 0.0016 Acc: 0.9638\n",
      "epoch dev loss: 0.0018 Acc: 0.9900\n",
      "Epoch 25/50\n",
      "----------\n",
      "epoch train loss: 0.0016 Acc: 0.9688\n",
      "epoch dev loss: 0.0020 Acc: 0.9650\n",
      "Epoch 26/50\n",
      "----------\n",
      "epoch train loss: 0.0012 Acc: 0.9787\n",
      "epoch dev loss: 0.0023 Acc: 0.9750\n",
      "Epoch 27/50\n",
      "----------\n",
      "epoch train loss: 0.0010 Acc: 0.9837\n",
      "epoch dev loss: 0.0013 Acc: 1.0000\n",
      "Epoch 28/50\n",
      "----------\n",
      "epoch train loss: 0.0009 Acc: 0.9812\n",
      "epoch dev loss: 0.0008 Acc: 0.9950\n",
      "Epoch 29/50\n",
      "----------\n",
      "epoch train loss: 0.0008 Acc: 0.9887\n",
      "epoch dev loss: 0.0005 Acc: 1.0000\n",
      "Epoch 30/50\n",
      "----------\n",
      "epoch train loss: 0.0007 Acc: 0.9937\n",
      "epoch dev loss: 0.0005 Acc: 1.0000\n",
      "Epoch 31/50\n",
      "----------\n",
      "epoch train loss: 0.0009 Acc: 0.9862\n",
      "epoch dev loss: 0.0004 Acc: 1.0000\n",
      "Epoch 32/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9975\n",
      "epoch dev loss: 0.0006 Acc: 1.0000\n",
      "Epoch 33/50\n",
      "----------\n",
      "epoch train loss: 0.0006 Acc: 0.9937\n",
      "epoch dev loss: 0.0004 Acc: 1.0000\n",
      "Epoch 34/50\n",
      "----------\n",
      "epoch train loss: 0.0008 Acc: 0.9925\n",
      "epoch dev loss: 0.0006 Acc: 1.0000\n",
      "Epoch 35/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9975\n",
      "epoch dev loss: 0.0005 Acc: 1.0000\n",
      "Epoch 36/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9962\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 37/50\n",
      "----------\n",
      "epoch train loss: 0.0006 Acc: 0.9937\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 38/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9962\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 39/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9962\n",
      "epoch dev loss: 0.0006 Acc: 1.0000\n",
      "Epoch 40/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9987\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 41/50\n",
      "----------\n",
      "epoch train loss: 0.0006 Acc: 0.9937\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 42/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9950\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 43/50\n",
      "----------\n",
      "epoch train loss: 0.0006 Acc: 0.9937\n",
      "epoch dev loss: 0.0002 Acc: 1.0000\n",
      "Epoch 44/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9962\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 45/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9975\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 46/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9975\n",
      "epoch dev loss: 0.0002 Acc: 1.0000\n",
      "Epoch 47/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9987\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 48/50\n",
      "----------\n",
      "epoch train loss: 0.0007 Acc: 0.9900\n",
      "epoch dev loss: 0.0002 Acc: 1.0000\n",
      "Epoch 49/50\n",
      "----------\n",
      "epoch train loss: 0.0005 Acc: 0.9962\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Epoch 50/50\n",
      "----------\n",
      "epoch train loss: 0.0004 Acc: 0.9975\n",
      "epoch dev loss: 0.0003 Acc: 1.0000\n",
      "Best dev Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epoches = 50\n",
    "batch_size = 32\n",
    "early_stop = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"net.pkl\"\n",
    "model_path = \"./output/best.pkl\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "# model = Meso4()\n",
    "# model = ResNetPretrained()\n",
    "model = models.resnet18()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "iteration = 0\n",
    "early_stop_flag = 0\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    print('Epoch {}/{}'.format(epoch+1, epoches))\n",
    "    print('-'*10)\n",
    "\n",
    "    # 模型训练\n",
    "    model=model.train()\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0.0\n",
    "\n",
    "    for (image, labels) in train_loader:\n",
    "\n",
    "        iter_loss = 0.0\n",
    "        iter_corrects = 0.0\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter_loss = loss.data.item()\n",
    "        train_loss += iter_loss\n",
    "        iter_corrects = torch.sum(preds == labels.data).to(torch.float32)\n",
    "        train_corrects += iter_corrects\n",
    "        iteration += 1\n",
    "        # if not (iteration % 20):\n",
    "            # print('iteration {} train loss: {:.4f} Acc: {:.4f}'.format(iteration, iter_loss / batch_size, iter_corrects / batch_size))\n",
    "    \n",
    "    epoch_loss = train_loss / train_dataset_size\n",
    "    epoch_acc = train_corrects / train_dataset_size\n",
    "    print('epoch train loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "    # 模型评估\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (image, labels) in dev_loader:\n",
    "\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.data.item()\n",
    "            val_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "            \n",
    "        epoch_loss = val_loss / dev_dataset_size\n",
    "        epoch_acc = val_corrects / dev_dataset_size\n",
    "        print('epoch dev loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "            early_stop_flag = 0\n",
    "        else:\n",
    "            early_stop_flag += 1 \n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # 每10个epoch保存模型的中间状态\n",
    "    # if not (epoch % 10):\n",
    "    #     torch.save(model.state_dict(), os.path.join(output_path, str(epoch) + '_' + model_name))\n",
    "    \n",
    "    if early_stop_flag >= early_stop:\n",
    "        break\n",
    "    \n",
    "print('Best dev Acc: {:.4f}'.format(best_acc))\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(output_path, \"best.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9013\n"
     ]
    }
   ],
   "source": [
    "model_path  = \"./output/best.pkl\"\n",
    "\n",
    "corrects = 0\n",
    "acc = 0\n",
    "# model = Meso4()\n",
    "model = models.resnet18()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    model = model.module\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for (image, labels) in test_loader:\n",
    "\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\n",
    "    acc = corrects / test_dataset_size\n",
    "    \n",
    "    print('Test Acc: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28b2a738dbd44a0630ad776ee6d4c28f43ef8560815f8e621d0df47ac60b54ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
